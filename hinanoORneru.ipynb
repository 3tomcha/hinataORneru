{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.57\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-test\tjapaneast\tdocs-aml\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'hinanoORneru'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), '')\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# %%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core import Run \n",
    "from utils import load_data\n",
    "from PIL import Image\n",
    "\n",
    "import os, glob\n",
    "\n",
    "WOMEN = [\"hinano\", \"neru\"]\n",
    "\n",
    "\n",
    "#美女クラス\n",
    "class BeautifulWomen:\n",
    "    def __init__(self, data, target, target_names, images):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.target_names = target_names\n",
    "        self.images = images\n",
    "\n",
    "    #キー(インスタンス変数)を取得するメソッド\n",
    "    def keys(self):\n",
    "        print(\"[data, target, target_names, images]\")\n",
    "        \n",
    "\n",
    "\n",
    "def load_beautiful_woman(dir):\n",
    "    data = []\n",
    "    target = []\n",
    "    target_names = [\"hinano\", \"neru\"]\n",
    "    images = []\n",
    "    \n",
    "    for label, woman in enumerate(WOMEN):\n",
    "        file_dir = dir + woman\n",
    "        files = glob.glob(file_dir + \"/*.jpeg\")\n",
    "        print(\"~~~~~~~~{}の画像をNumpy形式に変換し、Listに格納中~~~~~~~~\".format(woman))\n",
    "        for i, f in enumerate(files):\n",
    "            img = Image.open(f)\n",
    "            img = img.convert('L')          #画像をグレースケールに変換\n",
    "            #img = img.resize((128, 128))    #画像サイズの変更\n",
    "            imgdata = np.asarray(img)       #Numpy配列に変換\n",
    "            images.append(imgdata)          #画像データ: 128*128の2次元配列\n",
    "            data.append(imgdata.flatten())  #画像データ: 16,384の1次元配列\n",
    "            target.append(label)            #正解ラベルを格納\n",
    "\n",
    "    print(\"------------ListをNumpy形式に変換中--------------\")\n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "    target_names = np.array(target_names)\n",
    "    images = np.array(images)\n",
    "    #インスタンスを生成\n",
    "    beautifulWomen = BeautifulWomen(data, target, target_names, images)\n",
    "\n",
    "    return beautifulWomen\n",
    "\n",
    "\n",
    "test_women = load_beautiful_woman('images/test/')\n",
    "train_women = load_beautiful_woman('images/train/')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "# parser.add_argument('--test', type=BeautifulWomen, dest='test')\n",
    "# parser.add_argument('--train', type=BeautifulWomen, dest='train')\n",
    "parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regulation rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "X_train = train_women.data\n",
    "X_test = test_women.data\n",
    "y_train = train_women.target\n",
    "y_test = train_women.target\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "run = Run.get_context()\n",
    "print('Train a logistic regression model with regularization rate of', args.reg)\n",
    "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy is ', acc)\n",
    "\n",
    "run.log('regularization rate', np.float(args.reg))\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {\n",
    "    '--regularization': 0.5\n",
    "}\n",
    "\n",
    "\n",
    "est = SKLearn(source_directory=script_folder,\n",
    "             script_params=script_params,\n",
    "             compute_target=compute_target,\n",
    "             entry_script='train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting /mnt/azmnt/code/Users/live.com#tomocha.marika directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
     ]
    },
    {
     "ename": "TrainingException",
     "evalue": "TrainingException:\n\tMessage: ====================================================================\n\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\nYour project exceeds the file limit of 2000.\n\n====================================================================\n\n\n\tInnerException SnapshotException:\n\tMessage: ====================================================================\n\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\nYour project exceeds the file limit of 2000.\n\n====================================================================\n\n\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"====================================================================\\n\\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\\nYour project exceeds the file limit of 2000.\\n\\n====================================================================\\n\\n\"\n    }\n}\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"====================================================================\\n\\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\\nYour project exceeds the file limit of 2000.\\n\\n====================================================================\\n\\n\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTrainingException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4372e73856ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/_estimator_helper.py\u001b[0m in \u001b[0;36m_estimator_submit_method\u001b[0;34m(estimator, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m             source_directory_data_store=source_directory_data_store)\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mexperiment_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, workspace, experiment_name)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_submitted_runconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelemetry_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_override_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_directory_data_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, workspace, experiment_name, telemetry_values)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mexperiment_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAzureMLException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTrainingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTrainingException\u001b[0m: TrainingException:\n\tMessage: ====================================================================\n\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\nYour project exceeds the file limit of 2000.\n\n====================================================================\n\n\n\tInnerException SnapshotException:\n\tMessage: ====================================================================\n\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\nYour project exceeds the file limit of 2000.\n\n====================================================================\n\n\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"====================================================================\\n\\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\\nYour project exceeds the file limit of 2000.\\n\\n====================================================================\\n\\n\"\n    }\n}\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"====================================================================\\n\\nWhile attempting to take snapshot of /mnt/azmnt/code/Users/live.com#tomocha.marika\\nYour project exceeds the file limit of 2000.\\n\\n====================================================================\\n\\n\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
