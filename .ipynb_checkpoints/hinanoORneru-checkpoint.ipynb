{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.57\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-test\tjapaneast\tdocs-aml\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'hinanoORneru'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), 'hinanoORneru')\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/azmnt/code/Users/live.com#tomocha.marika/hinanoORneru/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core import Run \n",
    "from utils import load_data\n",
    "from PIL import Image\n",
    "\n",
    "import os, glob\n",
    "\n",
    "WOMEN = [\"hinano\", \"neru\"]\n",
    "\n",
    "\n",
    "#美女クラス\n",
    "class BeautifulWomen:\n",
    "    def __init__(self, data, target, target_names, images):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.target_names = target_names\n",
    "        self.images = images\n",
    "\n",
    "    #キー(インスタンス変数)を取得するメソッド\n",
    "    def keys(self):\n",
    "        print(\"[data, target, target_names, images]\")\n",
    "        \n",
    "\n",
    "\n",
    "def load_beautiful_woman(dir):\n",
    "    data = []\n",
    "    target = []\n",
    "    target_names = [\"hinano\", \"neru\"]\n",
    "    images = []\n",
    "    \n",
    "    for label, woman in enumerate(WOMEN):\n",
    "        file_dir = dir + woman\n",
    "        files = glob.glob(file_dir + \"/*.jpeg\")\n",
    "        print(\"~~~~~~~~{}の画像をNumpy形式に変換し、Listに格納中~~~~~~~~\".format(woman))\n",
    "        for i, f in enumerate(files):\n",
    "            img = Image.open(f)\n",
    "            img = img.convert('L')          #画像をグレースケールに変換\n",
    "            #img = img.resize((128, 128))    #画像サイズの変更\n",
    "            imgdata = np.asarray(img)       #Numpy配列に変換\n",
    "            images.append(imgdata)          #画像データ: 128*128の2次元配列\n",
    "            data.append(imgdata.flatten())  #画像データ: 16,384の1次元配列\n",
    "            target.append(label)            #正解ラベルを格納\n",
    "\n",
    "    print(\"------------ListをNumpy形式に変換中--------------\")\n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "    target_names = np.array(target_names)\n",
    "    images = np.array(images)\n",
    "    #インスタンスを生成\n",
    "    beautifulWomen = BeautifulWomen(data, target, target_names, images)\n",
    "\n",
    "    return beautifulWomen\n",
    "\n",
    "\n",
    "test_women = load_beautiful_woman('../images/test/')\n",
    "train_women = load_beautiful_woman('../images/train/')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "# parser.add_argument('--test', type=BeautifulWomen, dest='test')\n",
    "# parser.add_argument('--train', type=BeautifulWomen, dest='train')\n",
    "parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regulation rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "X_train = train_women.data\n",
    "X_test = test_women.data\n",
    "y_train = train_women.target\n",
    "y_test = train_women.target\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "run = Run.get_context()\n",
    "print('Train a logistic regression model with regularization rate of', args.reg)\n",
    "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy is ', acc)\n",
    "\n",
    "run.log('regularization rate', np.float(args.reg))\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {\n",
    "    '--regularization': 0.5\n",
    "}\n",
    "\n",
    "\n",
    "est = SKLearn(source_directory=script_folder,\n",
    "             script_params=script_params,\n",
    "             compute_target=compute_target,\n",
    "             entry_script='train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>hinanoORneru</td><td>hinanoORneru_1568091185_12087775</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/305275a6-842e-47d7-a66a-9fbf13304b55/resourceGroups/docs-aml/providers/Microsoft.MachineLearningServices/workspaces/image-test/experiments/hinanoORneru/runs/hinanoORneru_1568091185_12087775\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: hinanoORneru,\n",
       "Id: hinanoORneru_1568091185_12087775,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcf550042aa4261ae17cbb68990e42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
